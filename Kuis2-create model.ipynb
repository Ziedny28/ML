{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMqxaeQbFVen/vvwrAjlBP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ziedny28/ML/blob/master/Kuis2-create%20model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "RARm1Sl6DDd6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdB8KGqAD-g6",
        "outputId": "53505cd4-e481-4e3a-ccbe-f0e9672127ae"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/ML-Resources/training_data')"
      ],
      "metadata": {
        "id": "OlfLpaFaD_Ey"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Persiapan Dataset"
      ],
      "metadata": {
        "id": "XRa7ytq45lrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Define your desired image width and height\n",
        "your_image_width = 28\n",
        "your_image_height = 28\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Assuming the code is in the directory where the images are located\n",
        "current_directory = '/content/drive/My Drive/ML-Resources/training_data'\n",
        "\n",
        "for folder_name in os.listdir(current_directory):\n",
        "    folder_path = os.path.join(current_directory, folder_name)\n",
        "\n",
        "    i = 0\n",
        "    for img_name in tqdm(os.listdir(folder_path)):\n",
        "        i = i + 1\n",
        "        if i == 574:\n",
        "          break\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (your_image_width, your_image_height))\n",
        "        data.append(img)\n",
        "        labels.append(folder_name)\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6Y1VmHkEjMg",
        "outputId": "7560c9b1-7355-4380-ca1d-2e806e6e4f88"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 573/573 [00:01<00:00, 517.14it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 489.81it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 501.00it/s]\n",
            "100%|█████████▉| 573/574 [00:01<00:00, 489.82it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 497.35it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 519.74it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 454.51it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 510.76it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 428.08it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 454.61it/s]\n",
            "100%|██████████| 394/394 [00:00<00:00, 488.92it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 455.44it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 483.56it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 457.03it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 461.33it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 520.66it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 505.41it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 518.58it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 470.39it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 479.59it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 481.86it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 456.79it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 475.50it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 467.32it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 449.30it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 483.94it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 480.45it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 479.05it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 505.74it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 479.63it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 480.30it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 486.26it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 516.08it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 446.77it/s]\n",
            "100%|█████████▉| 573/575 [00:01<00:00, 414.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "kOLXweKGE-ix",
        "outputId": "46ec0a12-97b8-435f-d04a-0cc511e8f747"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b665cdd94b0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SRtAKxbeGcrG",
        "outputId": "ae064500-d3b5-4aae-da09-f85c53f4aab6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "1I2XnIneG0FN"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "2m1Blm-U5yWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess grayscale images\n",
        "data_gray = []\n",
        "\n",
        "for folder_name in os.listdir(current_directory):\n",
        "    folder_path = os.path.join(current_directory, folder_name)\n",
        "\n",
        "    i = 0\n",
        "    for img_name in tqdm(os.listdir(folder_path)):\n",
        "        i = i + 1\n",
        "        if i == 574:\n",
        "          break\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image as grayscale\n",
        "        img = cv2.resize(img, (your_image_width, your_image_height))\n",
        "        data_gray.append(img)\n",
        "\n",
        "data_gray = np.array(data_gray)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "data_gray = data_gray.astype('float32') / 255.0\n",
        "\n",
        "# Reshape data to include channel dimension\n",
        "data_gray = data_gray.reshape((data_gray.shape[0], your_image_width, your_image_height, 1))\n"
      ],
      "metadata": {
        "id": "78ONoXVjHt5C",
        "outputId": "03e09dba-d4c6-428b-bf15-50e18526e8e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 573/573 [00:00<00:00, 594.20it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 633.11it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 643.04it/s]\n",
            "100%|█████████▉| 573/574 [00:01<00:00, 555.89it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 604.26it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 606.91it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 600.87it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 616.46it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 623.43it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 621.68it/s]\n",
            "100%|██████████| 394/394 [00:00<00:00, 633.01it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 629.93it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 602.87it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 601.14it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 589.15it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 566.39it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 628.91it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 630.38it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 608.79it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 593.80it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 545.75it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 654.73it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 640.14it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 610.47it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 619.62it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 615.48it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 609.11it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 617.67it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 602.29it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 609.08it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 605.18it/s]\n",
            "100%|██████████| 573/573 [00:01<00:00, 519.64it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 625.55it/s]\n",
            "100%|██████████| 573/573 [00:00<00:00, 656.88it/s]\n",
            "100%|█████████▉| 573/575 [00:00<00:00, 632.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode"
      ],
      "metadata": {
        "id": "VqQTiU7LKfWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "labels_one_hot = to_categorical(labels_encoded, num_classes=num_classes)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_gray, X_test_gray, y_train, y_test = train_test_split(data_gray, labels_one_hot, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CcmL5fjCKenm"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation"
      ],
      "metadata": {
        "id": "esXjx0x-56x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "mLJg0wFqI3Iq"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(data)  # Fit the data augmentation pipeline to the reshaped training data"
      ],
      "metadata": {
        "id": "GTep9wC5MJAA"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build CNN Model"
      ],
      "metadata": {
        "id": "peWsPX5u6DEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes= 35"
      ],
      "metadata": {
        "id": "uU1LwHHgM3E9"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN Model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(your_image_width, your_image_height, 1)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))  # Using softmax for multi-class classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "# Train the model with data augmentation\n",
        "batch_size = 32\n",
        "history = model.fit(datagen.flow(X_train_gray, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=len(X_train_gray) // batch_size,\n",
        "                    epochs=20,\n",
        "                    validation_data=(X_test_gray, y_test),\n",
        "                    shuffle=True)\n",
        "\n",
        "# Save the model to an HDF5 file\n",
        "model.save('/content/drive/My Drive/ML-Resources/my_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR-opDVYI7Lm",
        "outputId": "b8d78ebd-e1ea-4086-9ac2-c9d12c303797"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "496/496 [==============================] - 10s 15ms/step - loss: 2.9684 - accuracy: 0.1445 - val_loss: 1.7418 - val_accuracy: 0.4681\n",
            "Epoch 2/20\n",
            "496/496 [==============================] - 8s 16ms/step - loss: 2.1122 - accuracy: 0.3281 - val_loss: 1.3085 - val_accuracy: 0.6064\n",
            "Epoch 3/20\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 1.8234 - accuracy: 0.4060 - val_loss: 1.0927 - val_accuracy: 0.6393\n",
            "Epoch 4/20\n",
            "496/496 [==============================] - 8s 17ms/step - loss: 1.6209 - accuracy: 0.4715 - val_loss: 0.9841 - val_accuracy: 0.6816\n",
            "Epoch 5/20\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 1.4992 - accuracy: 0.5100 - val_loss: 0.8334 - val_accuracy: 0.7387\n",
            "Epoch 6/20\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 1.4048 - accuracy: 0.5421 - val_loss: 0.7926 - val_accuracy: 0.7470\n",
            "Epoch 7/20\n",
            "496/496 [==============================] - 8s 17ms/step - loss: 1.3365 - accuracy: 0.5616 - val_loss: 0.7399 - val_accuracy: 0.7711\n",
            "Epoch 8/20\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 1.2581 - accuracy: 0.5877 - val_loss: 0.7196 - val_accuracy: 0.7676\n",
            "Epoch 9/20\n",
            "496/496 [==============================] - 8s 17ms/step - loss: 1.2108 - accuracy: 0.5994 - val_loss: 0.6458 - val_accuracy: 0.7920\n",
            "Epoch 10/20\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 1.1813 - accuracy: 0.6121 - val_loss: 0.6710 - val_accuracy: 0.7905\n",
            "Epoch 11/20\n",
            "496/496 [==============================] - 8s 17ms/step - loss: 1.1463 - accuracy: 0.6285 - val_loss: 0.6483 - val_accuracy: 0.7875\n",
            "Epoch 12/20\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 1.0973 - accuracy: 0.6403 - val_loss: 0.6260 - val_accuracy: 0.8071\n",
            "Epoch 13/20\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 1.0663 - accuracy: 0.6521 - val_loss: 0.6207 - val_accuracy: 0.7993\n",
            "Epoch 14/20\n",
            "496/496 [==============================] - 8s 17ms/step - loss: 1.0512 - accuracy: 0.6562 - val_loss: 0.5918 - val_accuracy: 0.8071\n",
            "Epoch 15/20\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 1.0125 - accuracy: 0.6625 - val_loss: 0.5871 - val_accuracy: 0.7978\n",
            "Epoch 16/20\n",
            "496/496 [==============================] - 8s 16ms/step - loss: 1.0042 - accuracy: 0.6726 - val_loss: 0.5424 - val_accuracy: 0.8242\n",
            "Epoch 17/20\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 0.9791 - accuracy: 0.6778 - val_loss: 0.5591 - val_accuracy: 0.8104\n",
            "Epoch 18/20\n",
            "496/496 [==============================] - 9s 17ms/step - loss: 0.9535 - accuracy: 0.6887 - val_loss: 0.5461 - val_accuracy: 0.8237\n",
            "Epoch 19/20\n",
            "496/496 [==============================] - 8s 15ms/step - loss: 0.9466 - accuracy: 0.6919 - val_loss: 0.5515 - val_accuracy: 0.8262\n",
            "Epoch 20/20\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 0.9233 - accuracy: 0.6936 - val_loss: 0.5628 - val_accuracy: 0.8056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "A4gOkroA6LWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have X_test_gray and y_test from the previous code\n",
        "# Ensure the input shape matches the model's input shape\n",
        "X_test_gray = X_test_gray.reshape((X_test_gray.shape[0], your_image_width, your_image_height, 1))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_gray, y_test)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Make predictions on a few samples\n",
        "num_samples_to_predict = 5\n",
        "sample_indices = np.random.choice(len(X_test_gray), num_samples_to_predict, replace=False)\n",
        "\n",
        "for idx in sample_indices:\n",
        "    sample = X_test_gray[idx].reshape(1, your_image_width, your_image_height, 1)\n",
        "    true_label = np.argmax(y_test[idx])  # Use argmax to get the index of the true label\n",
        "\n",
        "    # Predict the class probabilities\n",
        "    predictions = model.predict(sample)\n",
        "    predicted_label = np.argmax(predictions)\n",
        "\n",
        "    print(f'\\nSample {idx + 1}:')\n",
        "    print(f'True Label: {true_label}')\n",
        "    print(f'Predicted Label: {predicted_label}')\n",
        "    print(f'Class Probabilities: {predictions}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUmHm929JRaQ",
        "outputId": "248185fa-90f1-4868-bbf2-2003f2722ec5"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.8056\n",
            "Test Loss: 0.5628\n",
            "Test Accuracy: 80.56%\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "\n",
            "Sample 3037:\n",
            "True Label: 14\n",
            "Predicted Label: 14\n",
            "Class Probabilities: [[2.01470971e-06 3.92459668e-07 1.55460361e-06 1.13721344e-05\n",
            "  3.84675417e-07 5.27578406e-04 1.12921145e-04 1.59839303e-07\n",
            "  1.58744854e-06 7.17320887e-04 1.68266997e-05 2.60218568e-02\n",
            "  2.10705662e-06 2.24357173e-05 8.58839273e-01 4.06733277e-04\n",
            "  1.97879854e-04 1.78396044e-06 1.21534758e-05 9.11541491e-08\n",
            "  1.17597082e-07 7.29401828e-09 1.74886985e-08 1.86485568e-06\n",
            "  1.05694003e-01 2.94486163e-05 7.29434006e-03 7.88867910e-05\n",
            "  4.55843565e-06 1.46372914e-08 3.32915668e-08 4.15011858e-10\n",
            "  1.42608383e-10 8.59642526e-08 8.64404086e-08]]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "Sample 3450:\n",
            "True Label: 7\n",
            "Predicted Label: 7\n",
            "Class Probabilities: [[2.14759368e-07 6.92932634e-04 1.12215220e-03 1.49350613e-04\n",
            "  6.49931593e-08 4.17402340e-03 4.95821678e-06 9.00999010e-01\n",
            "  2.21369282e-06 2.34644180e-08 4.00823090e-08 2.93239651e-07\n",
            "  3.43985375e-05 6.84676434e-06 3.51509225e-05 2.79621986e-06\n",
            "  5.79086326e-08 9.87938474e-05 3.36606136e-05 3.32433527e-04\n",
            "  4.52842016e-07 9.81363185e-11 2.67970290e-06 2.78223183e-07\n",
            "  2.56094722e-07 7.84749616e-08 8.22445872e-06 1.29484397e-03\n",
            "  4.70385095e-03 1.23120465e-08 1.02655640e-07 6.18090079e-10\n",
            "  2.37253389e-05 1.42422692e-07 8.62760395e-02]]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "Sample 1914:\n",
            "True Label: 11\n",
            "Predicted Label: 26\n",
            "Class Probabilities: [[2.9992254e-05 5.4067151e-09 7.0569661e-07 2.2854860e-05 7.5319582e-07\n",
            "  2.7730601e-04 2.1177325e-03 2.7192243e-07 8.0792175e-05 4.7005455e-05\n",
            "  2.1691163e-04 9.2141576e-02 2.3718290e-05 1.9571744e-03 1.8344851e-01\n",
            "  3.3968484e-03 1.7301299e-02 2.2940398e-05 6.1428989e-05 1.0753056e-02\n",
            "  4.6848659e-06 2.9251485e-06 9.5145751e-06 1.2253577e-04 7.0779696e-03\n",
            "  3.0936575e-03 6.7581820e-01 4.5405526e-05 1.4582783e-03 2.1771637e-04\n",
            "  1.6841161e-05 1.7811076e-04 2.0789554e-05 3.1350988e-05 1.0463153e-06]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "Sample 2359:\n",
            "True Label: 20\n",
            "Predicted Label: 20\n",
            "Class Probabilities: [[5.2850804e-09 1.2813306e-04 9.4502628e-11 6.5343575e-10 9.2907442e-07\n",
            "  2.0626964e-12 1.6351480e-12 9.8963984e-09 9.3623695e-15 6.2060611e-13\n",
            "  3.9135730e-07 3.3337208e-10 1.4228169e-07 7.8402136e-06 4.0892804e-08\n",
            "  2.9431909e-08 3.1708698e-06 1.4753666e-04 1.4832218e-01 2.9819185e-09\n",
            "  8.4650338e-01 2.8086321e-08 3.3717942e-07 1.0036611e-08 3.3022964e-08\n",
            "  6.7491523e-10 5.3322213e-10 1.2844821e-10 5.8187419e-07 4.8835841e-03\n",
            "  4.1775385e-07 2.5017691e-11 4.2624362e-07 6.3536169e-07 2.2691405e-07]]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "Sample 3862:\n",
            "True Label: 0\n",
            "Predicted Label: 23\n",
            "Class Probabilities: [[1.08132794e-01 1.73171236e-06 3.44358142e-07 4.33641057e-12\n",
            "  6.54703236e-11 6.29936423e-08 1.64424523e-06 1.39175582e-09\n",
            "  1.21062817e-12 3.44667137e-06 4.56391433e-07 1.79584836e-09\n",
            "  1.35270968e-01 1.07033968e-01 2.04771422e-09 2.19337959e-02\n",
            "  1.66328507e-09 4.19754798e-07 3.44729779e-05 1.37751055e-09\n",
            "  1.18870094e-05 3.88551170e-11 9.43799563e-08 5.37163019e-01\n",
            "  1.23862455e-05 9.03789252e-02 1.53132717e-07 9.24485821e-09\n",
            "  1.53588542e-06 1.79064991e-05 1.19550441e-08 6.78896939e-11\n",
            "  7.54322039e-12 7.83246179e-09 1.46737689e-12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6r-XObULQ7k7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}